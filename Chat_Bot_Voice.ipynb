{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreN4vs/Telegran-Voice-Bot/blob/main/Chat_Bot_Voice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função para adicionar as  bibliotecas"
      ],
      "metadata": {
        "id": "YDJpUM1lb0jw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TZf0C4TZw_n"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_and_import(package):\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYu1hXe6OInu"
      },
      "source": [
        "# Instalações das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GiV1w1yCEp96"
      },
      "outputs": [],
      "source": [
        "install_and_import('openai-whisper')\n",
        "install_and_import('torch')\n",
        "install_and_import('pytelegrambotapi')\n",
        "install_and_import('python-telegram-bot==13.7')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JoOd5kBOm90"
      },
      "source": [
        "# Converter voz em texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p89F3-8EMlvW"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import whisper\n",
        "\n",
        "def transcrever_audio(audio_path):\n",
        "    # Carregando o modelo Whisper\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    # Transcrevendo o áudio\n",
        "    result = model.transcribe(audio_path)\n",
        "\n",
        "    # Retornando o texto transcrito\n",
        "    return result['text']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jetLQLNhPfQB"
      },
      "source": [
        "# Captar áudio do usuario\n",
        "\n",
        "> TESTE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvirpNoX2wBl"
      },
      "outputs": [],
      "source": [
        "\"\"\"import pyaudio\n",
        "import wave\n",
        "audio = pyaudio.PyAudio()\n",
        "\n",
        "stream = audio.open(\n",
        "    input=True,\n",
        "    format=pyaudio.paInt16,\n",
        "    channels=1,\n",
        "    rate=44000,\n",
        "    frames_per_buffer=1024,\n",
        ")\n",
        "\n",
        "frames = []\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        bloco = stream.read(1024)\n",
        "        frames.append(bloco)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "stream.start_stream()\n",
        "stream.close()\n",
        "audio.terminate()\n",
        "\n",
        "arquivo_final = wave.open(\"gravacao.wav\", \"wb\")\n",
        "arquivo_final.setnchannels(1)\n",
        "arquivo_final.setframerate(44000)\n",
        "arquivo_final.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
        "arquivo_final.writeframes(b\"\".join(frames))\n",
        "arquivo_final.close()\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfvj891lQz3Y"
      },
      "source": [
        "# Configuração do Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gM7lfExSZq9"
      },
      "outputs": [],
      "source": [
        "import telebot\n",
        "import json\n",
        "\n",
        "# Altere para o token do seu bot\n",
        "API_TOKEN = '7082441679:AAHGW6GnFHEW02r46Nk-rn8mL40CMuunJ7A'\n",
        "\n",
        "bot = telebot.TeleBot(API_TOKEN)\n",
        "\n",
        "@bot.message_handler(content_types=['audio', 'voice'])\n",
        "def handle_audio(message):\n",
        "    if message.content_type == 'audio':\n",
        "        file_info = bot.get_file(message.audio.file_id)\n",
        "    elif message.content_type == 'voice':\n",
        "        file_info = bot.get_file(message.voice.file_id)\n",
        "\n",
        "    # Baixar o arquivo de áudio\n",
        "    downloaded_file = bot.download_file(file_info.file_path)\n",
        "\n",
        "    # caminho onde o áudio será salvo\n",
        "    audio_file_path = f\"audio_{message.from_user.id}.ogg\"\n",
        "\n",
        "    # Salvar o áudio no servidor\n",
        "    with open(audio_file_path, 'wb') as new_file:\n",
        "        new_file.write(downloaded_file)\n",
        "\n",
        "    # Transcrever o áudio usando a função transcrever_audio\n",
        "    texto_transcrito = transcrever_audio(audio_file_path)\n",
        "\n",
        "    # Responder ao usuário com o texto transcrito\n",
        "    bot.reply_to(message, f\"Texto transcrito:\\n{texto_transcrito}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEyDYAbgYKUw"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmNIOW0HYET7"
      },
      "source": [
        "# Ativação do Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "japqhb-LYix2",
        "outputId": "9d5b9e11-69e1-45c9-a331-19ea0072c6a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 216MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ],
      "source": [
        "bot.polling()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPcgSuSIaptrFzUcfFX2u3W",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}